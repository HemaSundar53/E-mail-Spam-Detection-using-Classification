# IMPORT LIBRARIES
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# LOADING DATA
df = pd.read_csv("emails.csv")

# PRINTS NUMBER OF ROWS AND COLUMNS PRESENT IN THE DATASET
print('Rows,','Columns')
df.shape

df.head()

# CHECKING ALL THE FEATURES PRESENT
df.columns

# DROPPING NON-ESSENTIAL FEATURES
df.drop(['hou','connevey','jay','lay','allowing','ff','dry'],axis=1,inplace=True)

# CHECK FOR DUPLICATE VALUES AND REMOVE THEM
df.drop_duplicates(inplace = True)

# CHECK FOR NUMBER OF MISSING DATA OR NULL VALUES FOR EACH FEATURE
df.isnull().sum()

# IF NULL VALUES ARE PRESENT AND HAD TO BE REMOVED
'''
from sklearn.preprocessing import Imputer
im=Imputer(missing_values=np.nan,strategy='most_frequent',axis=0)
data['column_name']=im.fit_transform(data[['column_name']].values)
'''
# NO NULL VALUES ARE PRESENT

# VIEW BASIC STATISTICAL DETAILS
df.describe()

df.corr() 
# find the correlation between each attribute present including itself
# excludes null values by default

X = df.iloc[:,1:2995]
print(X)

Y = df.iloc[:,-1].values
print(Y)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size = 0.25,random_state=0)


### K-NEAREST NEIGHBOUR
knn=KNeighborsClassifier(n_neighbors=2)
knn.fit(X_train,y_train)
y_pred=knn.predict(X_test)
print("Accuracy score :")
print(accuracy_score(y_test,y_pred))

### NAIVE BAYES
mnb = MultinomialNB(alpha=1.9)
mnb.fit(X_train,y_train)
y_pred1 = mnb.predict(X_test)
print("Accuracy Score for Naive Bayes : ", accuracy_score(y_pred1,y_test))

### SUPPORT VECTOR MACHINE
svc = SVC(C=1.0,kernel='rbf',gamma='auto')         
svc.fit(X_train,y_train)
y_pred2 = svc.predict(X_test)
print("Accuracy Score for SVC : ", accuracy_score(y_pred2,y_test))

### DECISION TREE
dt=DecisionTreeClassifier(criterion='gini')
dt.fit(X_train,y_train)
y_pred3=dt.predict(X_test)
print("Accuracy Score :")
print(accuracy_score(y_pred3,y_test))

### RANDOM FOREST
rfc = RandomForestClassifier(n_estimators=100,criterion='gini')
rfc.fit(X_train,y_train)
y_pred4 = rfc.predict(X_test)
print("Accuracy Score of Random Forest Classifier : ", accuracy_score(y_pred4,y_test))
